{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":8003852,"sourceType":"datasetVersion","datasetId":4713606},{"sourceId":8033488,"sourceType":"datasetVersion","datasetId":4735372}],"dockerImageVersionId":30674,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nfrom torchvision.datasets import ImageFolder\nimport torchvision.transforms as transforms\nfrom torch.utils.data import Subset, DataLoader\nimport torchvision\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport wandb\nimport time\nimport torchvision.models as models","metadata":{"_uuid":"f92894f0-3dfb-4549-9c8e-0fcd1d79ec93","_cell_guid":"7cf28acc-d41e-4471-b43c-a98bbed26b6c","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"wandb.login(key=\"62cfafb7157dfba7fdd6132ac9d757ccd913aaaf\")","metadata":{"_uuid":"d8928a92-02b0-4c34-a0bd-58c8ef8facf2","_cell_guid":"008e21df-dc2c-4958-bbc4-b606b82ca2f4","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#configure the hyper parameters here\nh_params = {\n    \"epochs\":10,\n    \"learning_rate\":0.0001,\n    \"batch_size\":32,\n    \"model\":\"resnet50\",\n    \"last_unfreeze_layers\":1\n}\n\nIMAGE_SIZE = 224\nNUM_OF_CLASSES = 10","metadata":{"_uuid":"45e289d9-25ed-4681-a142-ba4437da8a31","_cell_guid":"5c20061e-cd8a-41a9-a02b-58830301229e","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#This method will spilt the training data into training and validation data\ndef split_dataset_with_class_distribution(dataset, split_ratio):\n    train_indices = []\n    val_indices = []\n\n    # Hardcoded class ranges based on the provided dataset\n    class_ranges = [\n        (0, 999),\n        (1000, 1999),\n        (2000, 2999),\n        (3000, 3999),\n        (4000, 4998),\n        (4999, 5998),\n        (5999, 6998),\n        (6999, 7998),\n        (7999, 8998),\n        (8999, 9998)\n    ]\n\n    for start, end in class_ranges:\n        class_indices = list(range(start, end + 1))\n        split_idx = int(len(class_indices) * split_ratio)\n        train_indices.extend(class_indices[:split_idx])\n        val_indices.extend(class_indices[split_idx:])\n\n    train_dataset = Subset(dataset, train_indices)\n    val_dataset = Subset(dataset, val_indices)\n    \n    return train_dataset, val_dataset\n\n#This method will generate train , validation, test data and returns it\ndef prepare_data(h_params):\n    desired_size = (IMAGE_SIZE, IMAGE_SIZE)\n    \n    train_transform = transforms.Compose([\n        transforms.Resize(desired_size),  \n        transforms.ToTensor()        \n    ])\n    \n    test_transform = transforms.Compose([\n        transforms.Resize(desired_size),  \n        transforms.ToTensor()        \n    ])\n\n    train_data_dir = \"/kaggle/input/nature1/inaturalist_12K/train\"\n    test_data_dir = \"/kaggle/input/nature1/inaturalist_12K/val\"\n    train_dataset_total = ImageFolder(train_data_dir, transform=train_transform)\n    train_dataset, validation_dataset = split_dataset_with_class_distribution(train_dataset_total, 0.8)\n\n    test_dataset = ImageFolder(test_data_dir, transform=test_transform)\n    train_len = len(train_dataset)\n    val_len = len(validation_dataset)\n    test_len = len(test_dataset)\n\n    batch_size =h_params[\"batch_size\"]\n    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n    val_loader = DataLoader(validation_dataset, batch_size=batch_size, shuffle=True)\n    test_loader =  DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n\n    # Return the datasets, loaders, and transforms as a dictionary\n    return {\n        \"train_len\": train_len,\n        \"val_len\": val_len,\n        \"test_len\": test_len,\n        \"train_loader\": train_loader,\n        \"val_loader\": val_loader,\n        \"test_loader\": test_loader\n    }\n","metadata":{"_uuid":"7bf9aca4-44ec-48d6-83fc-a11573b2055c","_cell_guid":"db40df95-5a34-4af7-a2f6-93df505fe844","collapsed":false,"_kg_hide-output":true,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#This will load Resnet50 model \ndef resnet50Model(h_params):\n    model = models.resnet50(pretrained=True)\n    num_ftrs = model.fc.in_features\n    model.fc = torch.nn.Linear(num_ftrs, NUM_OF_CLASSES)\n\n    # Freeze all layers\n    for param in model.parameters():\n        param.requires_grad = False\n\n    k = h_params[\"last_unfreeze_layers\"]\n    # Unfreeze the last k layers\n    if k > 0:\n        for param in list(model.parameters())[-k:]:\n            param.requires_grad = True\n\n    return model\n\n","metadata":{"_uuid":"5c8b457a-812e-4cbe-827a-06ca1f5dd96d","_cell_guid":"84a48d46-c7a5-4062-a270-debcddda14a1","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#this fucntion will train the model and logs accuracies to wandb\ndef train(h_params, training_data):\n    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n    model = resnet50Model(h_params)\n    model = torch.nn.DataParallel(model, device_ids = [0,1]).to(device)\n    loss_fn = nn.CrossEntropyLoss()\n    optimizer = torch.optim.Adam(model.parameters(), lr=h_params[\"learning_rate\"])\n    train_len = training_data['train_len']\n    val_len =  training_data['val_len']\n    train_loader = training_data['train_loader']\n    val_loader = training_data['val_loader']\n\n    for epoch in range(h_params[\"epochs\"]):\n        training_loss = 0.0\n        validation_loss = 0.0\n        train_correct = 0\n        validation_correct = 0\n         # Training phase\n        model.train()\n        for i, data in enumerate(train_loader, 0):\n            inputs, labels = data\n            inputs, labels = inputs.to(device), labels.to(device)\n\n            optimizer.zero_grad()\n            outputs = model(inputs)\n            loss = loss_fn(outputs, labels)\n            training_loss+=loss.item()\n            values, predicted = torch.max(outputs, 1)\n            crt = (predicted == labels).sum().item() \n            train_correct += crt\n            loss.backward()\n            optimizer.step()\n            if (i%10 == 0):\n                print( \"  epoch  \", epoch, \" batch \", i, \" accuracy \", crt/labels.shape[0], \" loss \", loss.item())\n\n          \n        # Validation phase\n        model.eval()\n        with torch.no_grad():\n            for data in val_loader:\n                inputs, labels = data\n                inputs, labels = inputs.to(device), labels.to(device)\n\n                outputs = model(inputs)\n                loss = loss_fn(outputs, labels)\n\n                values, predicted = torch.max(outputs, 1)\n                validation_correct += (predicted == labels).sum().item()\n                validation_loss += loss.item()\n        \n        train_accuracy = train_correct/train_len\n        train_loss  = training_loss/len(train_loader)\n        validation_accuracy = validation_correct/val_len\n        validation_loss = validation_loss/len(val_loader)\n        print(\"epoch: \", epoch, \"train accuray:\",train_accuracy , \"train loss:\",train_loss , \"val accuracy:\", validation_accuracy,\"val loss:\",validation_loss)\n        \n        #logging to wandb\n        wandb.log({\"train_accuracy\":train_accuracy, \"train_loss\":train_loss, \"val_accuracy\":validation_accuracy, \"val_loss\":validation_loss, \"epoch\":epoch})\n\n\n    print('Finished Training')\n    PATH = './model.pth'\n    torch.save(model.state_dict(), PATH)","metadata":{"_uuid":"a627d21f-95e2-43f6-a42d-6055af8d946c","_cell_guid":"78f72e9e-2d11-488f-b76f-d2349b4ca352","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"config = h_params\ntraining_data = prepare_data(config)\nrun = wandb.init(project=\"DL Assignment 2B\", name=f\"{config['model']}_ep_{config['epochs']}_bs_{config['batch_size']}_lr_{config['learning_rate']}_last_unfreeze_layers_{config['last_unfreeze_layers']}\", config=config)\ntrain(config, training_data) ","metadata":{"_uuid":"84ccc368-543e-4236-bed3-43ccafd73f3d","_cell_guid":"c7a5caf6-b1bb-4a04-8547-181c99eb7621","trusted":true},"execution_count":null,"outputs":[]}]}