{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":8003852,"sourceType":"datasetVersion","datasetId":4713606},{"sourceType":"datasetVersion","sourceId":8033488,"datasetId":4735372}],"dockerImageVersionId":30674,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nfrom torchvision.datasets import ImageFolder\nimport torchvision.transforms as transforms\nfrom torch.utils.data import Subset, DataLoader\nimport torchvision\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport wandb\nimport time\nimport torchvision.models as models\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-04-05T10:47:17.385333Z","iopub.execute_input":"2024-04-05T10:47:17.385719Z","iopub.status.idle":"2024-04-05T10:47:19.624595Z","shell.execute_reply.started":"2024-04-05T10:47:17.385690Z","shell.execute_reply":"2024-04-05T10:47:19.623055Z"},"trusted":true},"execution_count":4,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","Cell \u001b[0;32mIn[4], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchvision\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatasets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ImageFolder\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorchvision\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtransforms\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtransforms\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Subset, DataLoader\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorchvision\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torchvision/__init__.py:6\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmodulefinder\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Module\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchvision\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _meta_registrations, datasets, io, models, ops, transforms, utils\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mextension\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _HAS_OPS\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torchvision/models/__init__.py:2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01malexnet\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconvnext\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdensenet\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mefficientnet\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torchvision/models/convnext.py:9\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m functional \u001b[38;5;28;01mas\u001b[39;00m F\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmisc\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Conv2dNormActivation, Permute\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstochastic_depth\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m StochasticDepth\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtransforms\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_presets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ImageClassification\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _log_api_usage_once\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torchvision/ops/__init__.py:23\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgiou_loss\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m generalized_box_iou_loss\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmisc\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Conv2dNormActivation, Conv3dNormActivation, FrozenBatchNorm2d, MLP, Permute, SqueezeExcitation\n\u001b[0;32m---> 23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpoolers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MultiScaleRoIAlign\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mps_roi_align\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ps_roi_align, PSRoIAlign\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mps_roi_pool\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ps_roi_pool, PSRoIPool\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torchvision/ops/poolers.py:10\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchvision\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mboxes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m box_area\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _log_api_usage_once\n\u001b[0;32m---> 10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mroi_align\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m roi_align\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# copying result_idx_in_level to a specific index in result[]\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# is not supported by ONNX tracing yet.\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# _onnx_merge_levels() is an implementation supported by ONNX\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# that merges the levels to the right indices\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;129m@torch\u001b[39m\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39munused\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_onnx_merge_levels\u001b[39m(levels: Tensor, unmerged_results: List[Tensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torchvision/ops/roi_align.py:4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m List, Union\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_dynamo\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfx\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m nn, Tensor\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/_dynamo/__init__.py:2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m allowed_functions, convert_frame, eval_frame, resume_execution\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackends\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mregistry\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m list_backends, register_backend\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconvert_frame\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m replay\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py:46\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mguards\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CheckFunctionManager, GuardedCode\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhooks\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Hooks\n\u001b[0;32m---> 46\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moutput_graph\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m OutputGraph\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mreplay_record\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ExecutionRecord\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msymbolic_convert\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m InstructionTranslator\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/_dynamo/output_graph.py:35\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfx\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexperimental\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msymbolic_shapes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m free_symbols, ShapeEnv\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mweak\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m WeakIdKeyDictionary, WeakTensorKeyDictionary\n\u001b[0;32m---> 35\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m config, logging \u001b[38;5;28;01mas\u001b[39;00m torchdynamo_logging, variables\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackends\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mregistry\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CompiledFn, CompilerFn\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbytecode_transformation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     38\u001b[0m     create_call_function,\n\u001b[1;32m     39\u001b[0m     create_instruction,\n\u001b[1;32m     40\u001b[0m     Instruction,\n\u001b[1;32m     41\u001b[0m     unique_id,\n\u001b[1;32m     42\u001b[0m )\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/_dynamo/variables/__init__.py:53\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn_module\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m NNModuleVariable, UnspecializedNNModuleVariable\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtensor\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     47\u001b[0m     FakeItemVariable,\n\u001b[1;32m     48\u001b[0m     NumpyNdarrayVariable,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     51\u001b[0m     UnspecializedPythonVariable,\n\u001b[1;32m     52\u001b[0m )\n\u001b[0;32m---> 53\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtorch\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TorchVariable\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01muser_defined\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m UserDefinedClassVariable, UserDefinedObjectVariable\n\u001b[1;32m     56\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     57\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAutogradFunctionContextVariable\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     58\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAutogradFunctionVariable\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWithExitFunctionVariable\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    100\u001b[0m ]\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/_dynamo/variables/torch.py:124\u001b[0m\n\u001b[1;32m    112\u001b[0m tensor_dunder_fns_remap \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    113\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_TensorBase\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__radd__\u001b[39m: remap_as_fn___radd__,\n\u001b[1;32m    114\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_TensorBase\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__rmul__\u001b[39m: remap_as_fn___rmul__,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    117\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_TensorBase\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__rand__\u001b[39m: remap_as_fn___rand__,\n\u001b[1;32m    118\u001b[0m }\n\u001b[1;32m    121\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    122\u001b[0m     \u001b[38;5;66;03m# Wed need to monkeypatch transformers here, sadly.\u001b[39;00m\n\u001b[1;32m    123\u001b[0m     \u001b[38;5;66;03m# TODO(voz): Upstream to transformers lib\u001b[39;00m\n\u001b[0;32m--> 124\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m\n\u001b[1;32m    126\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_dynamo_overriden_transformers_eq\u001b[39m(\u001b[38;5;28mself\u001b[39m, other):\n\u001b[1;32m    127\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(other, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__dict__\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/__init__.py:26\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TYPE_CHECKING\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# Check the dependencies satisfy the minimal versions required.\u001b[39;00m\n\u001b[0;32m---> 26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m dependency_versions_check\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     28\u001b[0m     OptionalDependencyNotAvailable,\n\u001b[1;32m     29\u001b[0m     _LazyModule,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     47\u001b[0m     logging,\n\u001b[1;32m     48\u001b[0m )\n\u001b[1;32m     51\u001b[0m logger \u001b[38;5;241m=\u001b[39m logging\u001b[38;5;241m.\u001b[39mget_logger(\u001b[38;5;18m__name__\u001b[39m)  \u001b[38;5;66;03m# pylint: disable=invalid-name\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/dependency_versions_check.py:16\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright 2020 The HuggingFace Team. All rights reserved.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# See the License for the specific language governing permissions and\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdependency_versions_table\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m deps\n\u001b[0;32m---> 16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mversions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m require_version, require_version_core\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# define which module versions we always want to check at run time\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# (usually the ones defined in `install_requires` in setup.py)\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# order specific notes:\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# - tqdm must be checked before tokenizers\u001b[39;00m\n\u001b[1;32m     25\u001b[0m pkgs_to_check_at_runtime \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpython\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtqdm\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpyyaml\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     38\u001b[0m ]\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/utils/__init__.py:33\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconstants\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m IMAGENET_DEFAULT_MEAN, IMAGENET_DEFAULT_STD, IMAGENET_STANDARD_MEAN, IMAGENET_STANDARD_STD\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdoc\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     26\u001b[0m     add_code_sample_docstrings,\n\u001b[1;32m     27\u001b[0m     add_end_docstrings,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     31\u001b[0m     replace_return_docstrings,\n\u001b[1;32m     32\u001b[0m )\n\u001b[0;32m---> 33\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgeneric\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     34\u001b[0m     ContextManagers,\n\u001b[1;32m     35\u001b[0m     ExplicitEnum,\n\u001b[1;32m     36\u001b[0m     ModelOutput,\n\u001b[1;32m     37\u001b[0m     PaddingStrategy,\n\u001b[1;32m     38\u001b[0m     TensorType,\n\u001b[1;32m     39\u001b[0m     add_model_info_to_auto_map,\n\u001b[1;32m     40\u001b[0m     cached_property,\n\u001b[1;32m     41\u001b[0m     can_return_loss,\n\u001b[1;32m     42\u001b[0m     expand_dims,\n\u001b[1;32m     43\u001b[0m     find_labels,\n\u001b[1;32m     44\u001b[0m     flatten_dict,\n\u001b[1;32m     45\u001b[0m     infer_framework,\n\u001b[1;32m     46\u001b[0m     is_jax_tensor,\n\u001b[1;32m     47\u001b[0m     is_numpy_array,\n\u001b[1;32m     48\u001b[0m     is_tensor,\n\u001b[1;32m     49\u001b[0m     is_tf_symbolic_tensor,\n\u001b[1;32m     50\u001b[0m     is_tf_tensor,\n\u001b[1;32m     51\u001b[0m     is_torch_device,\n\u001b[1;32m     52\u001b[0m     is_torch_dtype,\n\u001b[1;32m     53\u001b[0m     is_torch_tensor,\n\u001b[1;32m     54\u001b[0m     reshape,\n\u001b[1;32m     55\u001b[0m     squeeze,\n\u001b[1;32m     56\u001b[0m     strtobool,\n\u001b[1;32m     57\u001b[0m     tensor_size,\n\u001b[1;32m     58\u001b[0m     to_numpy,\n\u001b[1;32m     59\u001b[0m     to_py_obj,\n\u001b[1;32m     60\u001b[0m     transpose,\n\u001b[1;32m     61\u001b[0m     working_or_temp_dir,\n\u001b[1;32m     62\u001b[0m )\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhub\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     64\u001b[0m     CLOUDFRONT_DISTRIB_PREFIX,\n\u001b[1;32m     65\u001b[0m     HF_MODULES_CACHE,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     91\u001b[0m     try_to_load_from_cache,\n\u001b[1;32m     92\u001b[0m )\n\u001b[1;32m     93\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mimport_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     94\u001b[0m     ACCELERATE_MIN_VERSION,\n\u001b[1;32m     95\u001b[0m     ENV_VARS_TRUE_AND_AUTO_VALUES,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    200\u001b[0m     torch_only_method,\n\u001b[1;32m    201\u001b[0m )\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/utils/generic.py:35\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mimport_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_torch_version, is_flax_available, is_tf_available, is_torch_available, is_torch_fx_proxy\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_flax_available():\n\u001b[0;32m---> 35\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mjax\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mjnp\u001b[39;00m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mcached_property\u001b[39;00m(\u001b[38;5;28mproperty\u001b[39m):\n\u001b[1;32m     39\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;124;03m    Descriptor that mimics @property but caches output in member variable.\u001b[39;00m\n\u001b[1;32m     41\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;124;03m    Built-in in functools from Python 3.8.\u001b[39;00m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/jax/__init__.py:39\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m _cloud_tpu_init\n\u001b[1;32m     36\u001b[0m \u001b[38;5;66;03m# Confusingly there are two things named \"config\": the module and the class.\u001b[39;00m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;66;03m# We want the exported object to be the class, so we first import the module\u001b[39;00m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;66;03m# to make sure a later import doesn't overwrite the class.\u001b[39;00m\n\u001b[0;32m---> 39\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mjax\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m config \u001b[38;5;28;01mas\u001b[39;00m _config_module\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m _config_module\n\u001b[1;32m     42\u001b[0m \u001b[38;5;66;03m# Force early import, allowing use of `jax.core` after importing `jax`.\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/jax/config.py:15\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright 2018 The JAX Authors.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# See the License for the specific language governing permissions and\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mjax\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_src\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfig\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m config \u001b[38;5;28;01mas\u001b[39;00m _deprecated_config  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# Deprecations\u001b[39;00m\n\u001b[1;32m     19\u001b[0m _deprecations \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;66;03m# Added October 27, 2023\u001b[39;00m\n\u001b[1;32m     21\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconfig\u001b[39m\u001b[38;5;124m\"\u001b[39m: (\n\u001b[1;32m     22\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAccessing jax.config via the jax.config submodule is deprecated.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     23\u001b[0m         _deprecated_config),\n\u001b[1;32m     24\u001b[0m }\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/jax/_src/config.py:28\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Any, Callable, Generic, NamedTuple, NoReturn, TypeVar\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mwarnings\u001b[39;00m\n\u001b[0;32m---> 28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mjax\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_src\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m lib\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mjax\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_src\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m jax_jit\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mjax\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_src\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m transfer_guard_lib\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/jax/_src/lib/__init__.py:75\u001b[0m\n\u001b[1;32m     70\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m _jaxlib_version\n\u001b[1;32m     73\u001b[0m version_str \u001b[38;5;241m=\u001b[39m jaxlib\u001b[38;5;241m.\u001b[39mversion\u001b[38;5;241m.\u001b[39m__version__\n\u001b[1;32m     74\u001b[0m version \u001b[38;5;241m=\u001b[39m check_jaxlib_version(\n\u001b[0;32m---> 75\u001b[0m   jax_version\u001b[38;5;241m=\u001b[39m\u001b[43mjax\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mversion\u001b[49m\u001b[38;5;241m.\u001b[39m__version__,\n\u001b[1;32m     76\u001b[0m   jaxlib_version\u001b[38;5;241m=\u001b[39mjaxlib\u001b[38;5;241m.\u001b[39mversion\u001b[38;5;241m.\u001b[39m__version__,\n\u001b[1;32m     77\u001b[0m   minimum_jaxlib_version\u001b[38;5;241m=\u001b[39mjax\u001b[38;5;241m.\u001b[39mversion\u001b[38;5;241m.\u001b[39m_minimum_jaxlib_version)\n\u001b[1;32m     79\u001b[0m \u001b[38;5;66;03m# Before importing any C compiled modules from jaxlib, first import the CPU\u001b[39;00m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;66;03m# feature guard module to verify that jaxlib was compiled in a way that only\u001b[39;00m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;66;03m# uses instructions that are present on this machine.\u001b[39;00m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mjaxlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcpu_feature_guard\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mcpu_feature_guard\u001b[39;00m\n","\u001b[0;31mAttributeError\u001b[0m: partially initialized module 'jax' has no attribute 'version' (most likely due to a circular import)"],"ename":"AttributeError","evalue":"partially initialized module 'jax' has no attribute 'version' (most likely due to a circular import)","output_type":"error"}]},{"cell_type":"code","source":"wandb.login(key=\"62cfafb7157dfba7fdd6132ac9d757ccd913aaaf\")","metadata":{"execution":{"iopub.status.busy":"2024-04-05T10:47:05.024915Z","iopub.status.idle":"2024-04-05T10:47:05.025266Z","shell.execute_reply.started":"2024-04-05T10:47:05.025086Z","shell.execute_reply":"2024-04-05T10:47:05.025109Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"h_params = {\n    \"epochs\":15,\n    \"learning_rate\":0.0001,\n    \"batch_size\":256,\n    \"actv_func\":\"relu\",\n    \"data_augumentation\":True,\n    \"dropout\":0.2,\n    \"fc_layer_size\":50,\n    \"model\":\"resnet50\",\n    \"last_unfreeze_layers\":1\n}\n\nIMAGE_SIZE = 299\nNUM_OF_CLASSES = 10","metadata":{"execution":{"iopub.status.busy":"2024-04-05T10:47:05.026643Z","iopub.status.idle":"2024-04-05T10:47:05.026943Z","shell.execute_reply.started":"2024-04-05T10:47:05.026794Z","shell.execute_reply":"2024-04-05T10:47:05.026807Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def split_dataset_with_class_distribution(dataset, split_ratio):\n    train_indices = []\n    val_indices = []\n\n    # Hardcoded class ranges based on the provided dataset\n    class_ranges = [\n        (0, 999),\n        (1000, 1999),\n        (2000, 2999),\n        (3000, 3999),\n        (4000, 4998),\n        (4999, 5998),\n        (5999, 6998),\n        (6999, 7998),\n        (7999, 8998),\n        (8999, 9998)\n    ]\n\n    for start, end in class_ranges:\n        class_indices = list(range(start, end + 1))\n        split_idx = int(len(class_indices) * split_ratio)\n        train_indices.extend(class_indices[:split_idx])\n        val_indices.extend(class_indices[split_idx:])\n\n    train_dataset = Subset(dataset, train_indices)\n    val_dataset = Subset(dataset, val_indices)\n    \n    return train_dataset, val_dataset\n\ndef prepare_data(h_params):\n    desired_size = (IMAGE_SIZE, IMAGE_SIZE)\n\n    if h_params[\"data_augumentation\"]:\n        train_transform = transforms.Compose([\n            transforms.Resize(desired_size),  \n             transforms.RandomHorizontalFlip(),\n            transforms.RandomVerticalFlip(),\n            transforms.RandomRotation(10),\n            transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n            transforms.GaussianBlur(kernel_size=3),\n            transforms.ToTensor()        \n        ])\n    else:\n         train_transform = transforms.Compose([\n            transforms.Resize(desired_size),  \n            transforms.ToTensor()        \n        ])\n\n    test_transform = transforms.Compose([\n        transforms.Resize(desired_size),  \n        transforms.ToTensor()        \n    ])\n\n    train_data_dir = \"/kaggle/input/nature1/inaturalist_12K/train\"\n    test_data_dir = \"/kaggle/input/nature1/inaturalist_12K/val\"\n    train_dataset_total = ImageFolder(train_data_dir, transform=train_transform)\n    train_dataset, validation_dataset = split_dataset_with_class_distribution(train_dataset_total, 0.8)\n\n    test_dataset = ImageFolder(test_data_dir, transform=test_transform)\n    train_len = len(train_dataset)\n    val_len = len(validation_dataset)\n    test_len = len(test_dataset)\n\n    batch_size =h_params[\"batch_size\"]\n    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n    val_loader = DataLoader(validation_dataset, batch_size=batch_size, shuffle=True)\n    test_loader =  DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n\n    # Return the datasets, loaders, and transforms as a dictionary\n    return {\n        \"train_len\": train_len,\n        \"val_len\": val_len,\n        \"test_len\": test_len,\n        \"train_loader\": train_loader,\n        \"val_loader\": val_loader,\n        \"test_loader\": test_loader\n    }\n\n\n\n#Preparing the data\n","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2024-04-05T10:47:05.028645Z","iopub.status.idle":"2024-04-05T10:47:05.028961Z","shell.execute_reply.started":"2024-04-05T10:47:05.028807Z","shell.execute_reply":"2024-04-05T10:47:05.028820Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def inceptionV3Model(h_params):\n    model = models.inception_v3(pretrained=True)\n    num_ftrs = model.fc.in_features\n    model.fc = torch.nn.Linear(num_ftrs, NUM_OF_CLASSES)\n\n    for param in model.parameters():\n    #         print(param)\n            param.requires_grad = False\n\n    # Unfreeze parameters of the fc layer\n    for param in model.fc.parameters():\n        param.requires_grad = True\n    return model\n\ndef resnet50Model(h_params):\n    model = models.resnet50(pretrained=True)\n    print(model)\n    num_ftrs = model.fc.in_features\n    model.fc = torch.nn.Linear(num_ftrs, NUM_OF_CLASSES)\n\n    for param in model.parameters():\n        param.requires_grad = False\n\n    # Unfreeze parameters of the fc layer\n    for param in model.fc.parameters():\n        param.requires_grad = True\n        \n    return model\n# resnet50Model(h_params)","metadata":{"execution":{"iopub.status.busy":"2024-04-05T10:47:05.030102Z","iopub.status.idle":"2024-04-05T10:47:05.030444Z","shell.execute_reply.started":"2024-04-05T10:47:05.030262Z","shell.execute_reply":"2024-04-05T10:47:05.030276Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nclass CNN(nn.Module):\n    def __init__(self, h_params):\n        super(CNN, self).__init__()\n        \n\n   \n        \n    def get_activation_function(self, activation_func_name):\n        if activation_func_name == 'elu':\n            return F.elu\n        elif activation_func_name == 'gelu':\n            return F.gelu\n        elif activation_func_name == 'silu':\n            return F.silu\n        elif activation_func_name == 'selu':\n            return F.selu\n        elif activation_func_name == 'leaky_relu':\n            return F.leaky_relu\n    \n    def neurons_in_dense_layer(self, filter_sizes, image_size):\n        for i in range(5):\n            image_size = int((image_size - filter_sizes[i] +1)/2)\n        return image_size","metadata":{"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2024-04-05T10:47:05.032095Z","iopub.status.idle":"2024-04-05T10:47:05.032412Z","shell.execute_reply.started":"2024-04-05T10:47:05.032242Z","shell.execute_reply":"2024-04-05T10:47:05.032254Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train(h_params, training_data):\n    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n    model = resnet50Model(h_params)\n    model = torch.nn.DataParallel(model, device_ids = [0,1]).to(device)\n    loss_fn = nn.CrossEntropyLoss()\n    optimizer = torch.optim.Adam(model.parameters(), lr=h_params[\"learning_rate\"])\n    train_len = training_data['train_len']\n    val_len =  training_data['val_len']\n    train_loader = training_data['train_loader']\n    val_loader = training_data['val_loader']\n\n    for epoch in range(h_params[\"epochs\"]):\n        training_loss = 0.0\n        validation_loss = 0.0\n        train_correct = 0\n        validation_correct = 0\n         # Training phase\n        model.train()\n        for i, data in enumerate(train_loader, 0):\n            inputs, labels = data\n            inputs, labels = inputs.to(device), labels.to(device)\n\n            optimizer.zero_grad()\n            outputs = model(inputs)\n            loss = loss_fn(outputs, labels)\n            training_loss+=loss.item()\n            values, predicted = torch.max(outputs, 1)\n            crt = (predicted == labels).sum().item() \n            train_correct += crt\n            loss.backward()\n            optimizer.step()\n            if (i%10 == 0):\n                print( \"                            epoch  \", epoch, \" batch \", i, \" accuracy \", crt/labels.shape[0], \" loss \", loss.item())\n\n          \n        # Validation phase\n        model.eval()\n        with torch.no_grad():\n            for data in val_loader:\n                inputs, labels = data\n                inputs, labels = inputs.to(device), labels.to(device)\n\n                outputs = model(inputs)\n                loss = loss_fn(outputs, labels)\n\n                values, predicted = torch.max(outputs, 1)\n                validation_correct += (predicted == labels).sum().item()\n                validation_loss += loss.item()\n        \n        train_accuracy = train_correct/train_len\n        train_loss  = training_loss/len(train_loader)\n        validation_accuracy = validation_correct/val_len\n        validation_loss = validation_loss/len(val_loader)\n        print(\"epoch: \", epoch, \"train accuray:\",train_accuracy , \"train loss:\",train_loss , \"val accuracy:\", validation_accuracy,\"val loss:\",validation_loss)\n        \n        #logging to wandb\n        wandb.log({\"train_accuracy\":train_accuracy, \"train_loss\":train_loss, \"val_accuracy\":validation_accuracy, \"val_loss\":validation_loss, \"epoch\":epoch})\n\n\n    print('Finished Training')\n    PATH = './model.pth'\n    torch.save(model.state_dict(), PATH)\n","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2024-04-05T10:47:05.033339Z","iopub.status.idle":"2024-04-05T10:47:05.033665Z","shell.execute_reply.started":"2024-04-05T10:47:05.033510Z","shell.execute_reply":"2024-04-05T10:47:05.033523Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"config = h_params\nconfig = {\n    \"epochs\":30,\n    \"learning_rate\":0.0001,\n    \"batch_size\":256,\n    \"actv_func\":\"relu\",\n    \"data_augumentation\":True,\n    \"dropout\":0.2,\n    \"fc_layer_size\":50,\n    \"model\":\"resnet50\",\n    \"last_unfreeze_layers\":1\n}\n\n\nstart_time = time.time()  # Record the start time\ntraining_data = prepare_data(config)\nrun = wandb.init(project=\"DL Assignment 2B\", name=f\"{config['model']}_ep_{config['epochs']}_lr_{config['learning_rate']}_last_unfreeze_layers_{config['last_unfreeze_layers']}_data_aug_{config['data_augumentation']}\", config=config)\ntrain(config, training_data) \nend_time = time.time()  # Record the end time\ntraining_time = end_time - start_time\nprint(f\"  Training time: {training_time/60} minutes , per epoch:{training_time/(60*10)} minutes\")","metadata":{"execution":{"iopub.status.busy":"2024-04-05T10:47:05.034709Z","iopub.status.idle":"2024-04-05T10:47:05.034995Z","shell.execute_reply.started":"2024-04-05T10:47:05.034851Z","shell.execute_reply":"2024-04-05T10:47:05.034863Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# sweep_params = {\n#     'method' : 'bayes',\n#     'name'   : 'DL assn 2 sweep',\n#     'metric' : {\n#         'goal' : 'maximize',\n#         'name' : 'val_accuracy',\n#     },\n#     'parameters' : {\n#         'epochs':{'values' : [10]},\n#         'learning_rate':{'values' : [0.0001, 0.001]},\n#         'batch_size':{'values':[128, 256, 512]},\n#         'num_of_filter':{'values' : [16,32,64] } ,\n#         'filter_size':{'values' : [[3,3,3,3,3], [5,5,5,5,5], [7,7,7,7,7], [11,9,7,5,3], [3,5,7,9,11]]},\n#         'actv_func':{'values':['elu','gelu','leaky_relu','selu']},\n#         'filter_multiplier':{'values' : [1,2,0.5]},\n#         'data_augumentation':{'values': [True, False]},\n#         'batch_normalization':{'values' : [True, False]},\n#         'dropout':{'values': [0,0.1,0.2]},\n#         'dense_layer_size':{'values' : [64, 128,256]},\n#         'conv_layers':{'values':[5]}\n#     }\n# }\n\n# sweep_id = wandb.sweep(sweep=sweep_params, project=\"DL Assignment 2B\")\n# print(sweep_id)\n# def main():\n#     wandb.init(project=\"DL Assignment 2B\" )\n#     config = wandb.config\n#     start_time = time.time()  # Record the start time\n#     with wandb.init(project=\"DL Assignment 2B\", name=f\"{config['actv_func']}_ep_{config['epochs']}_lr_{config['learning_rate']}_init_fltr_cnt_{config['num_of_filter']}_fltr_sz_{config['filter_size']}_fltr_mult_{config['filter_multiplier']}_data_aug_{config['data_augumentation']}_batch_norm_{config['batch_normalization']}_dropout_{config['dropout']}_dense_size_{config['dense_layer_size']}_batch_size_{config['batch_size']}\", config=config ):\n#         training_data = prepare_data(config)\n#         train(config,training_data)\n#     end_time = time.time()  # Record the end time\n#     training_time = end_time - start_time\n#     print(f\"  Training time: {training_time/60} minutes , per epoch:{training_time/(60*10)} minutes\")","metadata":{"execution":{"iopub.status.busy":"2024-04-05T10:47:05.036440Z","iopub.status.idle":"2024-04-05T10:47:05.036744Z","shell.execute_reply.started":"2024-04-05T10:47:05.036591Z","shell.execute_reply":"2024-04-05T10:47:05.036608Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# wandb.agent(\"iji9tba8\", function=main, count=50)\n","metadata":{"execution":{"iopub.status.busy":"2024-04-05T10:47:05.037885Z","iopub.status.idle":"2024-04-05T10:47:05.038192Z","shell.execute_reply.started":"2024-04-05T10:47:05.038040Z","shell.execute_reply":"2024-04-05T10:47:05.038053Z"},"trusted":true},"execution_count":null,"outputs":[]}]}