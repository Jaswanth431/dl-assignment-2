{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":8003852,"sourceType":"datasetVersion","datasetId":4713606}],"dockerImageVersionId":30674,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nfrom torchvision.datasets import ImageFolder\nimport torchvision.transforms as transforms\nfrom torch.utils.data import Subset, DataLoader\nimport torchvision\nimport torch.nn as nn\nimport torch.nn.functional as F","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-04-02T07:17:59.883869Z","iopub.execute_input":"2024-04-02T07:17:59.884619Z","iopub.status.idle":"2024-04-02T07:17:59.891634Z","shell.execute_reply.started":"2024-04-02T07:17:59.884583Z","shell.execute_reply":"2024-04-02T07:17:59.890627Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"h_params = {\n    \"epochs\":10,\n    \"learning_rate\":0.0001,\n    \"batch_size\":256,\n    \"num_of_filter\":32,\n    \"filter_size\":[5,5,5],\n    \"actv_func\":\"relu\",\n    \"filter_multiplier\":1,\n    \"data_augumentation\":False,\n    \"data_normalization\":False,\n    \"dropout\":0,\n    \"conv_layers\":3\n}","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define the desired size\nimage_size = 800\ndesired_size = (image_size, image_size)\n\n# Define transformations to be applied to the images\ntransform = transforms.Compose([\n    transforms.Resize(desired_size),  # Resize images to the desired size\n    transforms.ToTensor()        # Convert images to tensors\n])\n\n# Load the dataset from the folder\ndata_dir = \"/kaggle/input/nature/inaturalist_12K/train\"\ndataset = ImageFolder(data_dir, transform=transform)\ntotal_images = len(dataset)\n\nbatch_size =h_params[\"batch_size\"]\ntrain_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)","metadata":{"execution":{"iopub.status.busy":"2024-04-02T07:17:59.893918Z","iopub.execute_input":"2024-04-02T07:17:59.894171Z","iopub.status.idle":"2024-04-02T07:18:07.267304Z","shell.execute_reply.started":"2024-04-02T07:17:59.894149Z","shell.execute_reply":"2024-04-02T07:18:07.266326Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nclass CNN(nn.Module):\n    def __init__(self, h_params):\n        super(CNN, self).__init__()\n        \n        self.conv1 = nn.Conv2d(3, 6, 5)\n        self.pool = nn.MaxPool2d(2, 2)\n        self.conv2 = nn.Conv2d(6, 16, 5)\n        self.conv3 = nn.Conv2d(16, 32, 5)\n#          self.conv2 = nn.Conv2d(6, 16, 5)\n#         self.conv3 = nn.Conv2d(16, 32, 5)\n        f_map_side = self.neurons_in_dense_layer([5,5,5], image_size)\n        self.fc1 = nn.Linear(32 *f_map_side*f_map_side , 50)\n        self.fc2 = nn.Linear(50, 10)\n\n    def forward(self, x):\n        # -> n, 3, 32, 32\n#         print(\"input x\", x.shape)\n        x = self.pool(F.relu(self.conv1(x))) \n#         print(\"input c1\", x.shape)\n        x = self.pool(F.relu(self.conv2(x)))\n#         print(\"input c2\", x.shape)\n        x = self.pool(F.relu(self.conv3(x))) \n#         print(\"input c3\", x.shape)\n        f_map_side = self.neurons_in_dense_layer([5,5,5], image_size)\n        x = x.view(-1, 32  *f_map_side*f_map_side)   \n#         print(\"input v1\", x.shape)\n        x = F.relu(self.fc1(x))       \n#         print(\"input f1\", x.shape)\n        x = self.fc2(x)      \n#         print(\"input f2\", x.shape)\n        return x\n     def neurons_in_dense_layer(self, filter_sizes, image_size):\n        for i in range(3):\n            image_size = int((image_size - filter_sizes[i] +1)/2)\n        return image_size","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nmodel = CNN()\nmodel = torch.nn.DataParallel(model, device_ids = [0,1]).to(device)\nloss_fn = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=h_params[\"learning_rate\"])\n\n\n\nfor epoch in range(h_params[\"epochs\"]):\n    running_loss = 0.0\n    correct = 0\n    total = 0;\n    for i, data in enumerate(train_loader, 0):\n        inputs, labels = data\n        inputs, labels = inputs.to(device), labels.to(device)\n        total+=inputs.shape[0]\n\n        optimizer.zero_grad()\n#         print(\"input shape:\", inputs.shape)\n        # Forward pass\n        outputs = model(inputs)\n#         print(outputs)\n#         print(outputs.shape)\n#         print(labels)\n#         print(labels.shape)\n\n        loss = loss_fn(outputs, labels)\n\n        values, predicted = torch.max(outputs, 1)\n        correct += (predicted == labels).sum().item()\n        loss.backward()\n        optimizer.step()\n\n        if i%10 == 9:\n          print(\"epoch: \", epoch+1, \" batch no: \", i+1, \" loss: \", loss.item())\n    print(\"accuracy:\", correct/total_images)\nprint('Finished Training')\nPATH = './cnn.pth'\ntorch.save(model.state_dict(), PATH)\n","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2024-04-02T07:18:07.289954Z","iopub.execute_input":"2024-04-02T07:18:07.290294Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":" # Set the model to evaluation mode\nmodel.eval()\ncorrect = 0\nwith torch.no_grad():  # Disable gradient calculation to speed up computations\n  for inputs, labels in train_loader:\n      inputs, labels = inputs.to(device), labels.to(device)\n\n      # Forward pass\n      outputs = model(inputs)\n\n      # Compute the predicted labels\n      values, predicted = torch.max(outputs, 1)\n\n      # Update counts of correct and total predictions\n      correct += (predicted == labels).sum().item()\n\n# Calculate accuracy\naccuracy = correct / total_images\n\nprint(\"accuracy: \", accuracy)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}