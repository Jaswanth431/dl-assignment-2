{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"7cf28acc-d41e-4471-b43c-a98bbed26b6c","_uuid":"f92894f0-3dfb-4549-9c8e-0fcd1d79ec93","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["import torch\n","from torchvision.datasets import ImageFolder\n","import torchvision.transforms as transforms\n","from torch.utils.data import Subset, DataLoader\n","import torchvision\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import wandb\n","import time\n","import torchvision.models as models"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"008e21df-dc2c-4958-bbc4-b606b82ca2f4","_uuid":"d8928a92-02b0-4c34-a0bd-58c8ef8facf2","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["wandb.login(key=\"\")"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"5c20061e-cd8a-41a9-a02b-58830301229e","_uuid":"45e289d9-25ed-4681-a142-ba4437da8a31","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["#configure the hyper parameters here\n","h_params = {\n","    \"epochs\":10,\n","    \"learning_rate\":0.0001,\n","    \"batch_size\":32,\n","    \"model\":\"resnet50\",\n","    \"last_unfreeze_layers\":1\n","}\n","\n","IMAGE_SIZE = 224\n","NUM_OF_CLASSES = 10"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"db40df95-5a34-4af7-a2f6-93df505fe844","_kg_hide-output":true,"_uuid":"7bf9aca4-44ec-48d6-83fc-a11573b2055c","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["#This method will spilt the training data into training and validation data\n","def split_dataset_with_class_distribution(dataset, split_ratio):\n","    train_indices = []\n","    val_indices = []\n","\n","    # Hardcoded class ranges based on the provided dataset\n","    class_ranges = [\n","        (0, 999),\n","        (1000, 1999),\n","        (2000, 2999),\n","        (3000, 3999),\n","        (4000, 4998),\n","        (4999, 5998),\n","        (5999, 6998),\n","        (6999, 7998),\n","        (7999, 8998),\n","        (8999, 9998)\n","    ]\n","\n","    for start, end in class_ranges:\n","        class_indices = list(range(start, end + 1))\n","        split_idx = int(len(class_indices) * split_ratio)\n","        train_indices.extend(class_indices[:split_idx])\n","        val_indices.extend(class_indices[split_idx:])\n","\n","    train_dataset = Subset(dataset, train_indices)\n","    val_dataset = Subset(dataset, val_indices)\n","    \n","    return train_dataset, val_dataset\n","\n","#This method will generate train , validation, test data and returns it\n","def prepare_data(h_params):\n","    desired_size = (IMAGE_SIZE, IMAGE_SIZE)\n","    \n","    train_transform = transforms.Compose([\n","        transforms.Resize(desired_size),  \n","        transforms.ToTensor()        \n","    ])\n","    \n","    test_transform = transforms.Compose([\n","        transforms.Resize(desired_size),  \n","        transforms.ToTensor()        \n","    ])\n","\n","    train_data_dir = \"/kaggle/input/nature1/inaturalist_12K/train\"\n","    test_data_dir = \"/kaggle/input/nature1/inaturalist_12K/val\"\n","    train_dataset_total = ImageFolder(train_data_dir, transform=train_transform)\n","    train_dataset, validation_dataset = split_dataset_with_class_distribution(train_dataset_total, 0.8)\n","\n","    test_dataset = ImageFolder(test_data_dir, transform=test_transform)\n","    train_len = len(train_dataset)\n","    val_len = len(validation_dataset)\n","    test_len = len(test_dataset)\n","\n","    batch_size =h_params[\"batch_size\"]\n","    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n","    val_loader = DataLoader(validation_dataset, batch_size=batch_size, shuffle=True)\n","    test_loader =  DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n","\n","    # Return the datasets, loaders, and transforms as a dictionary\n","    return {\n","        \"train_len\": train_len,\n","        \"val_len\": val_len,\n","        \"test_len\": test_len,\n","        \"train_loader\": train_loader,\n","        \"val_loader\": val_loader,\n","        \"test_loader\": test_loader\n","    }\n"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"84a48d46-c7a5-4062-a270-debcddda14a1","_uuid":"5c8b457a-812e-4cbe-827a-06ca1f5dd96d","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["#This will load Resnet50 model \n","def resnet50Model(h_params):\n","    model = models.resnet50(pretrained=True)\n","    num_ftrs = model.fc.in_features\n","    model.fc = torch.nn.Linear(num_ftrs, NUM_OF_CLASSES)\n","\n","    # Freeze all layers\n","    for param in model.parameters():\n","        param.requires_grad = False\n","\n","    k = h_params[\"last_unfreeze_layers\"]\n","    # Unfreeze the last k layers\n","    if k > 0:\n","        for param in list(model.parameters())[-k:]:\n","            param.requires_grad = True\n","\n","    return model\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"78f72e9e-2d11-488f-b76f-d2349b4ca352","_uuid":"a627d21f-95e2-43f6-a42d-6055af8d946c","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["#this fucntion will train the model and logs accuracies to wandb\n","def train(h_params, training_data):\n","    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","    model = resnet50Model(h_params)\n","    model = torch.nn.DataParallel(model, device_ids = [0,1]).to(device)\n","    loss_fn = nn.CrossEntropyLoss()\n","    optimizer = torch.optim.Adam(model.parameters(), lr=h_params[\"learning_rate\"])\n","    train_len = training_data['train_len']\n","    val_len =  training_data['val_len']\n","    train_loader = training_data['train_loader']\n","    val_loader = training_data['val_loader']\n","\n","    for epoch in range(h_params[\"epochs\"]):\n","        training_loss = 0.0\n","        validation_loss = 0.0\n","        train_correct = 0\n","        validation_correct = 0\n","         # Training phase\n","        model.train()\n","        for i, data in enumerate(train_loader, 0):\n","            inputs, labels = data\n","            inputs, labels = inputs.to(device), labels.to(device)\n","\n","            optimizer.zero_grad()\n","            outputs = model(inputs)\n","            loss = loss_fn(outputs, labels)\n","            training_loss+=loss.item()\n","            values, predicted = torch.max(outputs, 1)\n","            crt = (predicted == labels).sum().item() \n","            train_correct += crt\n","            loss.backward()\n","            optimizer.step()\n","            if (i%10 == 0):\n","                print( \"  epoch  \", epoch, \" batch \", i, \" accuracy \", crt/labels.shape[0], \" loss \", loss.item())\n","\n","          \n","        # Validation phase\n","        model.eval()\n","        with torch.no_grad():\n","            for data in val_loader:\n","                inputs, labels = data\n","                inputs, labels = inputs.to(device), labels.to(device)\n","\n","                outputs = model(inputs)\n","                loss = loss_fn(outputs, labels)\n","\n","                values, predicted = torch.max(outputs, 1)\n","                validation_correct += (predicted == labels).sum().item()\n","                validation_loss += loss.item()\n","        \n","        train_accuracy = train_correct/train_len\n","        train_loss  = training_loss/len(train_loader)\n","        validation_accuracy = validation_correct/val_len\n","        validation_loss = validation_loss/len(val_loader)\n","        print(\"epoch: \", epoch, \"train accuray:\",train_accuracy , \"train loss:\",train_loss , \"val accuracy:\", validation_accuracy,\"val loss:\",validation_loss)\n","        \n","        #logging to wandb\n","        wandb.log({\"train_accuracy\":train_accuracy, \"train_loss\":train_loss, \"val_accuracy\":validation_accuracy, \"val_loss\":validation_loss, \"epoch\":epoch})\n","\n","\n","    print('Finished Training')\n","    PATH = './model.pth'\n","    torch.save(model.state_dict(), PATH)"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"c7a5caf6-b1bb-4a04-8547-181c99eb7621","_uuid":"84ccc368-543e-4236-bed3-43ccafd73f3d","trusted":true},"outputs":[],"source":["config = h_params\n","training_data = prepare_data(config)\n","run = wandb.init(project=\"DL Assignment 2B\", name=f\"{config['model']}_ep_{config['epochs']}_bs_{config['batch_size']}_lr_{config['learning_rate']}_last_unfreeze_layers_{config['last_unfreeze_layers']}\", config=config)\n","train(config, training_data) "]}],"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"datasetId":4713606,"sourceId":8003852,"sourceType":"datasetVersion"},{"datasetId":4735372,"sourceId":8033488,"sourceType":"datasetVersion"}],"dockerImageVersionId":30674,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
